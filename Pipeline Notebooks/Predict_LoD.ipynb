{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорты\n"
      ],
      "metadata": {
        "id": "UkB-5H5wP-Uo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNKjTzw8piu-",
        "outputId": "1055fcf7-492e-4378-d3de-b501576a1c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tZq9BPXcG-YQkV40ryIwVqPQUpWXCk1-\n",
            "To: /content/test/test_dataset_mc2.zip\n",
            "100% 876M/876M [00:05<00:00, 151MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
            "To: /content/requirements.txt\n",
            "100% 225/225 [00:00<00:00, 443kB/s]\n",
            "replace /content/test/__MACOSX/._eye_test? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!gdown 1tZq9BPXcG-YQkV40ryIwVqPQUpWXCk1- -O /content/test/\n",
        "!gdown 12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
        "!unzip -qq /content/test/test_dataset_mc2.zip -d /content/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r4Bwkt4pkq6"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import glob\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "import GPUtil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5MpBxb2MjsO"
      },
      "source": [
        "# Датасет\n",
        "\n",
        "Прежде чем разбираться с моделями, нам надо в первую очередь разобраться с тем, как грузить датасет. Давайте напишем класс в торче для этого."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hPHj1jRrqDT"
      },
      "source": [
        "## Класс датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS7LtxhL8WWh"
      },
      "outputs": [],
      "source": [
        "class EyeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: str, mode: str = \"train\", transform=None):\n",
        "        self.class_ids = {\"vessel\": 1}\n",
        "\n",
        "        self.mode = mode.lower()\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self._image_files = glob.glob(f\"{data_folder}/*.png\")\n",
        "        if self.mode == \"train\":\n",
        "            self._mask_files = glob.glob(f\"{data_folder}/*.geojson\")\n",
        "\n",
        "        image_file_ids = set([el.split(\".\")[0] for el in self._image_files])\n",
        "        if self.mode == \"train\":\n",
        "            mask_file_ids = set([el.split(\".\")[0] for el in self._mask_files])\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            intersecting_ids = list(image_file_ids.intersection(mask_file_ids))\n",
        "            self._image_files = [el + \".png\" for el in intersecting_ids]\n",
        "            self._mask_files = [el + \".geojson\" for el in intersecting_ids]\n",
        "\n",
        "    @staticmethod\n",
        "    def read_image(path: str) -> np.ndarray:\n",
        "        image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.array(image / 255, dtype=np.float32)\n",
        "        return image\n",
        "\n",
        "    @staticmethod \n",
        "    def parse_polygon(coordinates, image_size): \n",
        "        mask = np.zeros(image_size, dtype=np.float32) \n",
        "    \n",
        "        if len(coordinates) == 1: \n",
        "            points = [np.int32(coordinates)] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "        else: \n",
        "            points = [np.int32([coordinates[0]])] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "    \n",
        "            for polygon in coordinates[1:]: \n",
        "                points = [np.int32([polygon])] \n",
        "                cv2.fillPoly(mask, points, 0) \n",
        "    \n",
        "        return mask\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_mask(shape: dict, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для парсинга фигур из geojson файла\n",
        "        \"\"\"\n",
        "        mask = np.zeros(image_size, dtype=np.float32)\n",
        "        coordinates = shape['coordinates']\n",
        "        if shape['type'] == 'MultiPolygon':\n",
        "            for polygon in coordinates:\n",
        "                mask += EyeDataset.parse_polygon(polygon, image_size)\n",
        "        else:\n",
        "            mask += EyeDataset.parse_polygon(coordinates, image_size)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def read_layout(self, path: str, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для чтения geojson разметки и перевода в numpy маску\n",
        "        \"\"\"\n",
        "        with open(path, 'r', encoding='cp1251') as f:  # some files contain cyrillic letters, thus cp1251\n",
        "            json_contents = json.load(f)\n",
        "\n",
        "        num_channels = 1 + max(self.class_ids.values())\n",
        "        mask_channels = [np.zeros(image_size, dtype=np.float32) for _ in range(num_channels)]\n",
        "        mask = np.zeros(image_size, dtype=np.float32)\n",
        "\n",
        "        if type(json_contents) == dict and json_contents['type'] == 'FeatureCollection':\n",
        "            features = json_contents['features']\n",
        "        elif type(json_contents) == list:\n",
        "            features = json_contents\n",
        "        else:\n",
        "            features = [json_contents]\n",
        "\n",
        "        for shape in features:\n",
        "            channel_id = self.class_ids[\"vessel\"]\n",
        "            mask = self.parse_mask(shape['geometry'], image_size)\n",
        "            mask_channels[channel_id] = np.maximum(mask_channels[channel_id], mask)\n",
        "\n",
        "        mask_channels[0] = 1 - np.max(mask_channels[1:], axis=0)\n",
        "\n",
        "        return np.stack(mask_channels, axis=-1)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        # Достаём имя файла по индексу\n",
        "        image_path = self._image_files[idx]\n",
        "\n",
        "        # Получаем соответствующий файл разметки\n",
        "        if self.mode == \"train\":\n",
        "            json_path = image_path.replace(\"png\", \"geojson\")\n",
        "\n",
        "        image = self.read_image(image_path)\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            mask = self.read_layout(json_path, image.shape[:2])\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            sample = {'image': image,\n",
        "                      'mask': mask}\n",
        "        else:\n",
        "            sample = {\"image\": image}\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._image_files)\n",
        "\n",
        "    # Метод для проверки состояния датасета\n",
        "    def make_report(self):\n",
        "      reports = []\n",
        "      if (not self.data_folder):\n",
        "        reports.append(\"Путь к датасету не указан\")\n",
        "      if (len(self._image_files) == 0):\n",
        "        reports.append(\"Изображения для распознавания не найдены\")\n",
        "      else:\n",
        "        reports.append(f\"Найдено {len(self._image_files)} изображений\")\n",
        "      cnt_images_without_masks = sum([1 - len(glob.glob(filepath.replace(\"png\", \"geojson\"))) for filepath in self._image_files])\n",
        "      if cnt_images_without_masks > 0:\n",
        "        reports.append(f\"Найдено {cnt_images_without_masks} изображений без разметки\")\n",
        "      else:\n",
        "        reports.append(f\"Для всех изображений есть файл разметки\")\n",
        "      return reports\n",
        "\n",
        "\n",
        "class DatasetPart(Dataset):\n",
        "    \"\"\"\n",
        "    Обертка над классом датасета для его разбиения на части\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset,\n",
        "                 indices: np.ndarray,\n",
        "                 transform: A.Compose = None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        sample = self.dataset[self.indices[idx]]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msq76dphpPKj"
      },
      "source": [
        "# Предикшн"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5U9g7lMpPKl"
      },
      "source": [
        "## Класс Предиктора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvCJt1AbpPKm"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class UnetPredictor:\n",
        "    def __init__(self, model: nn.Module, device: str):\n",
        "        self.model = model\n",
        "        self.device = torch.device(device)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def predict(self, dataloader: torch.utils.data.DataLoader) -> np.ndarray:\n",
        "        self.model.eval()\n",
        "\n",
        "        preds = []\n",
        "        print(len(dataloader))\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(dataloader):\n",
        "                image = batch[\"image\"].to(self.device)\n",
        "                output = self.model(image).cpu()\n",
        "                preds.append(torch.exp(output[:,1]))\n",
        "                del output\n",
        "                gc.collect()\n",
        "        return torch.cat(preds, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqMtkry9pPKn"
      },
      "source": [
        "##Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lWw-4548i2ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJp8ZTh4pPKo"
      },
      "outputs": [],
      "source": [
        "test_data = '/content/test/eye_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SR2zN3M_qNEZ"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/drive/MyDrive/Competitions/LeadersOfDigital/models/pretrain/model.pt')\n",
        "#model_2 = torch.load('/content/drive/MyDrive/Competitions/LeadersOfDigital/models/model_1024px_10x_1438.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL42Fa_fpPKp",
        "outputId": "cfb9b842-ec52-4a0b-a447-59426a376ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [02:39<00:00,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "cores=multiprocessing.cpu_count()\n",
        "size= 1024\n",
        "eval_aug = A.Compose([\n",
        "    A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    ToTensorV2(transpose_mask=True)\n",
        "])\n",
        "\n",
        "transforms = {\"test\": eval_aug}\n",
        "\n",
        "test_dataset = EyeDataset(\n",
        "    test_data, mode='predict', transform=transforms['test']\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                            batch_size=1,\n",
        "                                            num_workers=cores-1,\n",
        "                                            shuffle=False)\n",
        "\n",
        "predictor = UnetPredictor(model=model, device=\"cuda\")\n",
        "#predictor2 = UnetPredictor(model=model_2, device=\"cuda\")\n",
        "preds = predictor.predict(test_loader)\n",
        "del test_loader\n",
        "del eval_aug\n",
        "gc.collect()\n",
        "#preds_2 = predictor2.predict(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4980ad27-0c46-4ad7-81a0-48d2600efb57",
        "id": "VBvTjCqWFXaC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [02:35<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "eval_aug = A.Compose([\n",
        "    A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.HorizontalFlip(always_apply=True),\n",
        "    ToTensorV2(transpose_mask=True)\n",
        "])\n",
        "\n",
        "transforms = {\"test\": eval_aug}\n",
        "test_dataset = EyeDataset(\n",
        "    test_data, mode='predict', transform=transforms['test']\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                            batch_size=1,\n",
        "                                            num_workers=cores-1,\n",
        "                                            shuffle=False)\n",
        "predictor = UnetPredictor(model=model, device=\"cuda\")\n",
        "#predictor2 = UnetPredictor(model=model_2, device=\"cuda\")\n",
        "preds_fliph = predictor.predict(test_loader)\n",
        "del test_loader\n",
        "del eval_aug\n",
        "gc.collect()\n",
        "#preds_2 = predictor2.predict(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_aug = A.Compose([\n",
        "    A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.VerticalFlip(always_apply=True),\n",
        "    ToTensorV2(transpose_mask=True)\n",
        "])\n",
        "\n",
        "transforms = {\"test\": eval_aug}\n",
        "test_dataset = EyeDataset(\n",
        "    test_data, mode='predict', transform=transforms['test']\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                            batch_size=1,\n",
        "                                            num_workers=cores-1,\n",
        "                                            shuffle=False)\n",
        "predictor = UnetPredictor(model=model, device=\"cuda\")\n",
        "#predictor2 = UnetPredictor(model=model_2, device=\"cuda\")\n",
        "preds_flipv = predictor.predict(test_loader)\n",
        "del test_loader\n",
        "del eval_aug\n",
        "#preds_2 = predictor2.predict(test_loader)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Beoews8AGF1n",
        "outputId": "39823792-5f52-409b-8d5d-3ce97172e29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [02:36<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_aug = A.Compose([\n",
        "    A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.VerticalFlip(always_apply=True),\n",
        "    A.HorizontalFlip(always_apply=True),\n",
        "    ToTensorV2(transpose_mask=True)\n",
        "])\n",
        "transforms = {\"test\": eval_aug}\n",
        "test_dataset = EyeDataset(\n",
        "    test_data, mode='predict', transform=transforms['test']\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                            batch_size=1,\n",
        "                                            num_workers=cores-1,\n",
        "                                            shuffle=False)\n",
        "predictor = UnetPredictor(model=model, device=\"cuda\")\n",
        "#predictor2 = UnetPredictor(model=model_2, device=\"cuda\")\n",
        "preds_flipvh = predictor.predict(test_loader)\n",
        "del test_loader\n",
        "del eval_aug\n",
        "gc.collect()\n",
        "#preds_2 = predictor2.predict(test_loader)"
      ],
      "metadata": {
        "id": "6yEtJ4U4GPWw",
        "outputId": "33018534-28b5-455a-a7b1-ae8fc1004734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [02:37<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=1),\n",
        "])\n",
        "preds_fliph = transform(image=preds_fliph)['image']\n",
        "del transform\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcXA-tk1eigx",
        "outputId": "5fe4702a-4ee2-4151-d391-09459a45c74f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.VerticalFlip(p=1)\n",
        "])\n",
        "preds_flipv = transform(image=preds_flipv)['image']\n",
        "del transform\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "hVq3-LgVfliR",
        "outputId": "d922c1a0-bf2b-4980-99f6-0cbe0c2ceab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2q0Ry1Mz7sTu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.VerticalFlip(p=1),\n",
        "    A.HorizontalFlip(p=1)\n",
        "])\n",
        "preds_flipvh = transform(image=preds_flipvh)['image']\n",
        "del transform\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "dFlh_eOQflrw",
        "outputId": "8b3b04fb-38e0-44ef-c7fd-3c507eac2661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round_preds=(preds+preds_fliph+preds_flipv+preds_flipvh)/4"
      ],
      "metadata": {
        "id": "zdI9FZlSlIQv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''transform = A.Compose([\n",
        "    A.VerticalFlip(p=1),\n",
        "])\n",
        "round_preds = transform(image=round_preds)['image']\n",
        "del transform\n",
        "gc.collect()'''"
      ],
      "metadata": {
        "id": "2Zi5oYGw6YSD",
        "outputId": "0ed2e388-aeba-435f-e9e9-b768fefa4861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treshhold = 0.5\n",
        "round_preds[round_preds>=treshhold]=255\n",
        "round_preds[round_preds<treshhold]=0"
      ],
      "metadata": {
        "id": "QTWl9yCgOr8s"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/preds"
      ],
      "metadata": {
        "id": "LH663tC0O2wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc863e3f-c87f-45b9-a6f6-d2b8af5f0903"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/preds’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MVqw2U_zpPKq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "quality = 0.1\n",
        "box = (0, (size-777)/2, size, size-(size-777)/2)\n",
        "for i in range(len(round_preds)):\n",
        "    im = Image.fromarray(round_preds[i])\n",
        "    im = im.convert('1')\n",
        "    im = im.crop(box)\n",
        "    im = im.resize((1624,1232))\n",
        "    im.save(test_dataset._image_files[i].replace(\"/content/test/eye_test\", '/content/preds'),compress_level=9 ,bits=2, format=\"PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -9 -q -r test_submit.zip /content/preds/"
      ],
      "metadata": {
        "id": "D-JI08O2Q_VZ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "l5MpBxb2MjsO",
        "3hPHj1jRrqDT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}