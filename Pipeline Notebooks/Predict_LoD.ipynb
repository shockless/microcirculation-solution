{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорты\n"
      ],
      "metadata": {
        "id": "UkB-5H5wP-Uo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNKjTzw8piu-",
        "outputId": "7c68140e-2d9f-4943-e181-fa12295896b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tZq9BPXcG-YQkV40ryIwVqPQUpWXCk1-\n",
            "To: /content/test/test_dataset_mc2.zip\n",
            "100% 876M/876M [00:03<00:00, 291MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
            "To: /content/requirements.txt\n",
            "100% 225/225 [00:00<00:00, 416kB/s]\n",
            "Archive:  /content/test/test_dataset_mc2.zip\n",
            "replace /content/test/__MACOSX/._eye_test? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!gdown 1tZq9BPXcG-YQkV40ryIwVqPQUpWXCk1- -O /content/test/\n",
        "!gdown 12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
        "!unzip /content/test/test_dataset_mc2.zip -d /content/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9r4Bwkt4pkq6",
        "outputId": "a654883b-6c08-4a58-a1fe-4fab26c9bd32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 2)) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 5)) (4.6.0.66)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 6)) (0.0)\n",
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 10)) (7.9.0)\n",
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 13)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 14)) (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 15)) (0.12.1+cu113)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations->-r /content/requirements.txt (line 1)) (0.18.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations->-r /content/requirements.txt (line 1)) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations->-r /content/requirements.txt (line 1)) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations->-r /content/requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations->-r /content/requirements.txt (line 1)) (0.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations->-r /content/requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations->-r /content/requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations->-r /content/requirements.txt (line 1)) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations->-r /content/requirements.txt (line 1)) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations->-r /content/requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations->-r /content/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r /content/requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r /content/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r /content/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/requirements.txt (line 2)) (2022.2.1)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch->-r /content/requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch->-r /content/requirements.txt (line 7)) (0.4.12)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch->-r /content/requirements.txt (line 7)) (0.7.4)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch->-r /content/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r /content/requirements.txt (line 14)) (2.23.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from IPython->-r /content/requirements.txt (line 10)) (0.18.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->-r /content/requirements.txt (line 10)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->-r /content/requirements.txt (line 10)) (0.2.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->-r /content/requirements.txt (line 12)) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->-r /content/requirements.txt (line 12)) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->-r /content/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/requirements.txt (line 14)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/requirements.txt (line 14)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/requirements.txt (line 14)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/requirements.txt (line 14)) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r /content/requirements.txt (line 14)) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import glob\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "import GPUtil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5MpBxb2MjsO"
      },
      "source": [
        "# Датасет\n",
        "\n",
        "Прежде чем разбираться с моделями, нам надо в первую очередь разобраться с тем, как грузить датасет. Давайте напишем класс в торче для этого."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hPHj1jRrqDT"
      },
      "source": [
        "## Класс датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IS7LtxhL8WWh"
      },
      "outputs": [],
      "source": [
        "class EyeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: str, mode: str = \"train\", transform=None):\n",
        "        self.class_ids = {\"vessel\": 1}\n",
        "\n",
        "        self.mode = mode.lower()\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self._image_files = glob.glob(f\"{data_folder}/*.png\")\n",
        "        if self.mode == \"train\":\n",
        "            self._mask_files = glob.glob(f\"{data_folder}/*.geojson\")\n",
        "\n",
        "        image_file_ids = set([el.split(\".\")[0] for el in self._image_files])\n",
        "        if self.mode == \"train\":\n",
        "            mask_file_ids = set([el.split(\".\")[0] for el in self._mask_files])\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            intersecting_ids = list(image_file_ids.intersection(mask_file_ids))\n",
        "            self._image_files = [el + \".png\" for el in intersecting_ids]\n",
        "            self._mask_files = [el + \".geojson\" for el in intersecting_ids]\n",
        "\n",
        "    @staticmethod\n",
        "    def read_image(path: str) -> np.ndarray:\n",
        "        image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.array(image / 255, dtype=np.float32)\n",
        "        return image\n",
        "\n",
        "    @staticmethod \n",
        "    def parse_polygon(coordinates, image_size): \n",
        "        mask = np.zeros(image_size, dtype=np.float32) \n",
        "    \n",
        "        if len(coordinates) == 1: \n",
        "            points = [np.int32(coordinates)] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "        else: \n",
        "            points = [np.int32([coordinates[0]])] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "    \n",
        "            for polygon in coordinates[1:]: \n",
        "                points = [np.int32([polygon])] \n",
        "                cv2.fillPoly(mask, points, 0) \n",
        "    \n",
        "        return mask\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_mask(shape: dict, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для парсинга фигур из geojson файла\n",
        "        \"\"\"\n",
        "        mask = np.zeros(image_size, dtype=np.float32)\n",
        "        coordinates = shape['coordinates']\n",
        "        if shape['type'] == 'MultiPolygon':\n",
        "            for polygon in coordinates:\n",
        "                mask += EyeDataset.parse_polygon(polygon, image_size)\n",
        "        else:\n",
        "            mask += EyeDataset.parse_polygon(coordinates, image_size)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def read_layout(self, path: str, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для чтения geojson разметки и перевода в numpy маску\n",
        "        \"\"\"\n",
        "        with open(path, 'r', encoding='cp1251') as f:  # some files contain cyrillic letters, thus cp1251\n",
        "            json_contents = json.load(f)\n",
        "\n",
        "        num_channels = 1 + max(self.class_ids.values())\n",
        "        mask_channels = [np.zeros(image_size, dtype=np.float32) for _ in range(num_channels)]\n",
        "        mask = np.zeros(image_size, dtype=np.float32)\n",
        "\n",
        "        if type(json_contents) == dict and json_contents['type'] == 'FeatureCollection':\n",
        "            features = json_contents['features']\n",
        "        elif type(json_contents) == list:\n",
        "            features = json_contents\n",
        "        else:\n",
        "            features = [json_contents]\n",
        "\n",
        "        for shape in features:\n",
        "            channel_id = self.class_ids[\"vessel\"]\n",
        "            mask = self.parse_mask(shape['geometry'], image_size)\n",
        "            mask_channels[channel_id] = np.maximum(mask_channels[channel_id], mask)\n",
        "\n",
        "        mask_channels[0] = 1 - np.max(mask_channels[1:], axis=0)\n",
        "\n",
        "        return np.stack(mask_channels, axis=-1)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        # Достаём имя файла по индексу\n",
        "        image_path = self._image_files[idx]\n",
        "\n",
        "        # Получаем соответствующий файл разметки\n",
        "        if self.mode == \"train\":\n",
        "            json_path = image_path.replace(\"png\", \"geojson\")\n",
        "\n",
        "        image = self.read_image(image_path)\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            mask = self.read_layout(json_path, image.shape[:2])\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            sample = {'image': image,\n",
        "                      'mask': mask}\n",
        "        else:\n",
        "            sample = {\"image\": image}\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._image_files)\n",
        "\n",
        "    # Метод для проверки состояния датасета\n",
        "    def make_report(self):\n",
        "      reports = []\n",
        "      if (not self.data_folder):\n",
        "        reports.append(\"Путь к датасету не указан\")\n",
        "      if (len(self._image_files) == 0):\n",
        "        reports.append(\"Изображения для распознавания не найдены\")\n",
        "      else:\n",
        "        reports.append(f\"Найдено {len(self._image_files)} изображений\")\n",
        "      cnt_images_without_masks = sum([1 - len(glob.glob(filepath.replace(\"png\", \"geojson\"))) for filepath in self._image_files])\n",
        "      if cnt_images_without_masks > 0:\n",
        "        reports.append(f\"Найдено {cnt_images_without_masks} изображений без разметки\")\n",
        "      else:\n",
        "        reports.append(f\"Для всех изображений есть файл разметки\")\n",
        "      return reports\n",
        "\n",
        "\n",
        "class DatasetPart(Dataset):\n",
        "    \"\"\"\n",
        "    Обертка над классом датасета для его разбиения на части\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset,\n",
        "                 indices: np.ndarray,\n",
        "                 transform: A.Compose = None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        sample = self.dataset[self.indices[idx]]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msq76dphpPKj"
      },
      "source": [
        "# Предикшн"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5U9g7lMpPKl"
      },
      "source": [
        "## Класс Предиктора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BvCJt1AbpPKm"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "class UnetPredictor:\n",
        "    def __init__(self, model: nn.Module, device: str):\n",
        "        self.model = model\n",
        "        self.device = torch.device(device)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def predict(self, dataloader: torch.utils.data.DataLoader) -> np.ndarray:\n",
        "        self.model.eval()\n",
        "\n",
        "        preds = []\n",
        "        print(len(dataloader))\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(dataloader):\n",
        "                image = batch[\"image\"].to(self.device)\n",
        "                output = self.model(image).cpu()\n",
        "                preds.append(torch.exp(output[:,1]))\n",
        "                del image\n",
        "                del output\n",
        "                gc.collect()\n",
        "        return torch.cat(preds, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqMtkry9pPKn"
      },
      "source": [
        "##Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lWw-4548i2ie",
        "outputId": "44860e5e-6ae5-4f2a-9875-e1bdcb3218d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "nAnZL82a2JV0",
        "outputId": "b97c532e-816c-4bfe-fc76-c7bc90c722ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BJp8ZTh4pPKo"
      },
      "outputs": [],
      "source": [
        "test_data = '/content/test/eye_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SR2zN3M_qNEZ"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/drive/MyDrive/Competitions/LeadersOfDigital/models/model_batch_2_6.pt')\n",
        "#model_2 = torch.load('/content/drive/MyDrive/Competitions/LeadersOfDigital/models/model_1024px_10x_1438.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size=1024\n",
        "cores=multiprocessing.cpu_count()\n",
        "augs = [[[A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    ToTensorV2(transpose_mask=True)],\n",
        "    [A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.HorizontalFlip(p=1),\n",
        "    ToTensorV2(transpose_mask=True)],\n",
        "    [A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.VerticalFlip(p=1),\n",
        "    ToTensorV2(transpose_mask=True)],\n",
        "    [A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(size, size),\n",
        "    A.VerticalFlip(p=1),\n",
        "    A.HorizontalFlip(p=1),\n",
        "    ToTensorV2(transpose_mask=True)]\n",
        "],[[],\n",
        "   [A.HorizontalFlip(p=1)],\n",
        "   [A.VerticalFlip(p=1)],\n",
        "   [A.VerticalFlip(p=1),A.HorizontalFlip(p=1)]]]"
      ],
      "metadata": {
        "id": "Hc3tAU-IT_Yb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=[]"
      ],
      "metadata": {
        "id": "PvmJIjgYY-Q0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D0JzhtVWhvPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(augs[0])-2):\n",
        "    torch.cuda.empty_cache()\n",
        "    eval_aug = A.Compose(augs[0][i])\n",
        "    transforms = {\"test\": eval_aug}\n",
        "    test_dataset = EyeDataset(test_data, mode='predict', transform=transforms['test'])\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                            batch_size=1,\n",
        "                                            num_workers=cores-1,\n",
        "                                            shuffle=False)\n",
        "    predictor = UnetPredictor(model=model, device=\"cuda\")\n",
        "    prediction = predictor.predict(test_loader)\n",
        "    for j in range(1, len(prediction)-2): \n",
        "        transforms = A.Compose(augs[1][i])\n",
        "        prediction[j] = transforms(image=prediction[j])['image']\n",
        "    preds.append(prediction)\n",
        "    del test_loader, eval_aug, predictor, test_dataset,transforms\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "JWHUhZH4T6vu",
        "outputId": "18263a3a-4798-466a-c103-4796cafd29a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 68/301 [00:29<01:21,  2.86it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round_preds = []"
      ],
      "metadata": {
        "id": "1XSBohTvbZfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round_preds= np.copy((preds[0]+preds[1])/2)"
      ],
      "metadata": {
        "id": "zdI9FZlSlIQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "cGZk__GDTRAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treshhold = 0.5\n",
        "round_preds[round_preds>=treshhold]=255\n",
        "round_preds[round_preds<treshhold]=0"
      ],
      "metadata": {
        "id": "QTWl9yCgOr8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/preds"
      ],
      "metadata": {
        "id": "LH663tC0O2wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVqw2U_zpPKq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "quality = 0.1\n",
        "test_dataset = EyeDataset(\n",
        "    test_data, mode='predict'\n",
        ")\n",
        "box = (0, (size-777)/2, size, size-(size-777)/2)\n",
        "for i in range(len(round_preds)):\n",
        "    im = Image.fromarray(round_preds[i])\n",
        "    im = im.convert('1')\n",
        "    im = im.crop(box)\n",
        "    im = im.resize((1624,1232))\n",
        "    im.save(test_dataset._image_files[i].replace(\"/content/test/eye_test\", '/content/preds'),compress_level=9 ,bits=2, format=\"PNG\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "Vre5YXL_52dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -9 -q -r test_submit.zip /content/preds"
      ],
      "metadata": {
        "id": "D-JI08O2Q_VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sy98XTR5lotS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "l5MpBxb2MjsO",
        "3hPHj1jRrqDT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}