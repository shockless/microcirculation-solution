{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shockless/microcirculation-solution/blob/main/Pipeline%20Notebooks/Pretrain_LoD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEsHWyFJX6xD"
      },
      "source": [
        "# Подготовка сессии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Vh2CoDrycd"
      },
      "source": [
        "## Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juB9-lqxVhnp",
        "outputId": "e4bd1374-b375-49ee-a478-4511ac714424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj-PbsdAXlbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e15fbd9-9683-4baf-841c-25312c4cc5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
            "To: /content/requirements.txt\n",
            "\r  0% 0.00/225 [00:00<?, ?B/s]\r100% 225/225 [00:00<00:00, 413kB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 12hNXcrHr0v48m9VRr-GLj5eq3pnYU7Im\n",
        "!pip install -r /content/requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MhT-S1YLnWYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import glob\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "import GPUtil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAoCqzAWH7du"
      },
      "source": [
        "# Класс тренировщика модели"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Callable, defaultdict\n",
        "from typing import Tuple, Optional, List, Any, Iterator, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "vBQDkFvN3fqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "class UnetTrainer:\n",
        "    \"\"\"\n",
        "    Класс, реализующий обучение модели\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model: nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 criterion,\n",
        "                 device: str,\n",
        "                 metric_functions = [],\n",
        "                 epoch_number: int = 0,\n",
        "                 lr_scheduler = None):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        self.device = device\n",
        "\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.metric_functions = metric_functions\n",
        "\n",
        "        self.epoch_number = epoch_number\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_batch(self, val_iterator: Iterator, eval_on_n_batches: int) -> Optional[Dict[str, float]]:     \n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for real_batch_number in range(eval_on_n_batches):\n",
        "            try:\n",
        "                batch = next(val_iterator)\n",
        "\n",
        "                xs = batch['image'].to(self.device)\n",
        "                ys_true = batch['mask'].to(self.device)\n",
        "            except StopIteration:\n",
        "                if real_batch_number == 0:\n",
        "                    return None\n",
        "                else:\n",
        "                    break\n",
        "            ys_pred = self.model.eval()(xs)\n",
        "            loss = self.criterion(ys_pred, ys_true)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            predictions.append(ys_pred.cpu())\n",
        "            targets.append(ys_true.cpu())\n",
        "\n",
        "        predictions = torch.cat(predictions, dim=0)\n",
        "        targets = torch.cat(targets, dim=0)\n",
        "\n",
        "        metrics = {'loss': np.mean(losses)}\n",
        "\n",
        "        for metric_name, metric_fn in self.metric_functions:\n",
        "            metrics[metric_name] = metric_fn(predictions, targets).item()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate(self, val_loader, eval_on_n_batches: int = 1) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Вычисление метрик для эпохи\n",
        "        \"\"\"\n",
        "        metrics_sum = defaultdict(float)\n",
        "        num_batches = 0\n",
        "\n",
        "        val_iterator = iter(val_loader)\n",
        "\n",
        "        while True:\n",
        "            batch_metrics = self.evaluate_batch(val_iterator, eval_on_n_batches)\n",
        "\n",
        "            if batch_metrics is None:\n",
        "                break\n",
        "\n",
        "            for metric_name in batch_metrics:\n",
        "                metrics_sum[metric_name] += batch_metrics[metric_name]\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "        metrics = {}\n",
        "\n",
        "        for metric_name in metrics_sum:\n",
        "            metrics[metric_name] = metrics_sum[metric_name] / num_batches\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def fit_batch(self, train_iterator: Iterator, update_every_n_batches: int) -> Optional[Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Тренировка модели на одном батче\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "    \n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for real_batch_number in range(update_every_n_batches):\n",
        "            self.optimizer.zero_grad()\n",
        "            try:\n",
        "                batch = next(train_iterator)\n",
        "\n",
        "                xs = batch['image'].to(self.device)\n",
        "                ys_true = batch['mask'].to(self.device)\n",
        "            except StopIteration:\n",
        "                if real_batch_number == 0:\n",
        "                    return None\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            ys_pred = self.model.train()(xs)\n",
        "            loss = self.criterion(ys_pred, ys_true)\n",
        "\n",
        "            (loss / update_every_n_batches).backward()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            predictions.append(ys_pred.cpu())\n",
        "            targets.append(ys_true.cpu())\n",
        "\n",
        "        self.optimizer.step()\n",
        "        predictions = torch.cat(predictions, dim=0)\n",
        "        targets = torch.cat(targets, dim=0)\n",
        "\n",
        "        metrics = {'loss': np.mean(losses)}\n",
        "\n",
        "        for metric_name, metric_fn in self.metric_functions:\n",
        "            metrics[metric_name] = metric_fn(predictions, targets).item()\n",
        "        print(metrics)\n",
        "        return metrics\n",
        "\n",
        "    def fit_epoch(self, train_loader, update_every_n_batches: int = 1) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Одна эпоха тренировки модели\n",
        "        \"\"\"\n",
        "\n",
        "        metrics_sum = defaultdict(float)\n",
        "        num_batches = 0\n",
        "\n",
        "        train_iterator = iter(train_loader)\n",
        "        n_batches = len(train_loader)\n",
        "        with tqdm(total=n_batches) as pbar:\n",
        "            while True:\n",
        "                batch_metrics = self.fit_batch(train_iterator, update_every_n_batches)\n",
        "\n",
        "                if batch_metrics is None:\n",
        "                    break\n",
        "\n",
        "                for metric_name in batch_metrics:\n",
        "                    metrics_sum[metric_name] += batch_metrics[metric_name]\n",
        "\n",
        "                pbar.update(1)\n",
        "                num_batches += 1\n",
        "\n",
        "        metrics = {}\n",
        "\n",
        "        for metric_name in metrics_sum:\n",
        "            metrics[metric_name] = metrics_sum[metric_name] / num_batches\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def fit(self, train_loader, num_epochs: int,\n",
        "            val_loader = None, update_every_n_batches: int = 1,\n",
        "            ) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Метод, тренирующий модель и вычисляющий метрики для каждой эпохи\n",
        "        \"\"\"\n",
        "\n",
        "        summary = defaultdict(list)\n",
        "\n",
        "        def save_metrics(metrics: Dict[str, float], postfix: str = '') -> None:\n",
        "          # Сохранение метрик в summary\n",
        "            nonlocal summary, self\n",
        "\n",
        "            for metric in metrics:\n",
        "                metric_name, metric_value = f'{metric}{postfix}', metrics[metric]\n",
        "\n",
        "                summary[metric_name].append(metric_value)\n",
        "\n",
        "        for _ in tqdm(range(num_epochs - self.epoch_number), initial=self.epoch_number, total=num_epochs):\n",
        "            self.epoch_number += 1\n",
        "\n",
        "            train_metrics = self.fit_epoch(train_loader, update_every_n_batches)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                save_metrics(train_metrics, postfix='_train')\n",
        "\n",
        "                if val_loader is not None:\n",
        "                    test_metrics = self.evaluate(val_loader)\n",
        "                    save_metrics(test_metrics, postfix='_test')\n",
        "\n",
        "            if self.lr_scheduler is not None:\n",
        "                self.lr_scheduler.step()\n",
        "\n",
        "        summary = {metric: np.array(summary[metric]) for metric in summary}\n",
        "\n",
        "        return summary\n"
      ],
      "metadata": {
        "id": "2QgNIeS63ZYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TWl-2tSVQlD"
      },
      "source": [
        "# Метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zltdk2x2VTzY"
      },
      "outputs": [],
      "source": [
        "# F1-мера\n",
        "class SoftDice:\n",
        "    def __init__(self, epsilon=1e-8):\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def __call__(self, predictions: List[Dict[str, torch.Tensor]],\n",
        "                 targets: List[Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
        "        numerator = torch.sum(2 * predictions * targets)\n",
        "        denominator = torch.sum(predictions + targets)\n",
        "        return numerator / (denominator + self.epsilon)\n",
        "\n",
        "# Метрика полноты\n",
        "class Recall:\n",
        "    def __init__(self, epsilon=1e-81):\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def __call__(self, predictions: List[Dict[str, torch.Tensor]],\n",
        "                 targets: List[Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
        "        numerator = torch.sum(predictions * targets)\n",
        "        denominator = torch.sum(targets)\n",
        "\n",
        "        return numerator / (denominator + self.epsilon)\n",
        "\n",
        "# Метрика точности\n",
        "class Accuracy:\n",
        "    def __init__(self, epsilon=1e-8):\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def __call__(self, predictions: list, targets: list) -> torch.Tensor:\n",
        "        numerator = torch.sum(predictions * targets)\n",
        "        denominator = torch.sum(predictions)\n",
        "\n",
        "        return numerator / (denominator + self.epsilon)\n",
        "\n",
        "def make_metrics():\n",
        "    soft_dice = SoftDice()\n",
        "    recall = Recall()\n",
        "    accuracy = Accuracy()\n",
        "\n",
        "    def exp_dice(pred, target):\n",
        "        return soft_dice(torch.exp(pred[:, 1:]), target[:, 1:])\n",
        "\n",
        "    def exp_accuracy(pred, target):\n",
        "        return accuracy(torch.exp(pred[:, 1:]), target[:, 1:])\n",
        "\n",
        "    def exp_recall(pred, target):\n",
        "        return recall(torch.exp(pred[:, 1:]), target[:, 1:])\n",
        "\n",
        "    return [('dice', exp_dice),\n",
        "            ('accuracy', exp_accuracy),\n",
        "            ('recall', exp_recall),\n",
        "            ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Датасет претрейна\n"
      ],
      "metadata": {
        "id": "evbYchORoWMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PngEyeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_folder: str,\n",
        "                 mode: str = \"train\",\n",
        "                 dataset_names=['HRF', 'ChaseDB', 'ORVS', 'DR-Hagis', 'IOSTAR', 'ARIA', 'DRIVE'],\n",
        "                 transform=None):\n",
        "        self.class_ids = {\"vessel\": 1}\n",
        "\n",
        "        self.mode = mode.lower()\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        self.dataset_names = dataset_names\n",
        "        self._image_files = []\n",
        "        self._mask_files = []\n",
        "        \"\"\"\n",
        "        DATASET/\n",
        "        ....Test/\n",
        "        ........Original/\n",
        "        ............Images/\n",
        "        ............Labels/\n",
        "        ....Train/\n",
        "        ........Original/\n",
        "        ............Images/\n",
        "        ............Labels/\n",
        "        \"\"\"\n",
        "\n",
        "        for dataset_name in self.dataset_names:\n",
        "            dataset_path = f\"{data_folder}/{dataset_name}\"\n",
        "            test_part = f\"{dataset_path}/Test/Original\"\n",
        "            train_part = f\"{dataset_path}/Train/Original\"\n",
        "\n",
        "            images_files = list(\n",
        "                sorted([f\"{train_part}/Images/\" + path for path in os.listdir(f\"{train_part}/Images/\")] + \\\n",
        "                       [f\"{test_part}/Images/\" + path for path in os.listdir(f\"{test_part}/Images/\")]))\n",
        "\n",
        "            self._image_files.extend(images_files)\n",
        "\n",
        "            if self.mode == \"train\":\n",
        "                mask_files = list(\n",
        "                    sorted([f\"{train_part}/Labels/\" + path for path in os.listdir(f\"{train_part}/Labels/\")] + \\\n",
        "                           [f\"{test_part}/Labels/\" + path for path in os.listdir(f\"{test_part}/Labels/\")]))\n",
        "\n",
        "                self._mask_files.extend(mask_files)\n",
        "\n",
        "    @staticmethod\n",
        "    def read_image(path: str) -> np.ndarray:\n",
        "        image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.array(image / 255, dtype=np.float32)\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def read_mask(path: str) -> np.ndarray:\n",
        "        mask = np.expand_dims(cv2.threshold(cv2.imread(path, cv2.IMREAD_GRAYSCALE), 128, 255, cv2.THRESH_BINARY)[1], 2)\n",
        "        mask = np.concatenate(((255 - mask), mask), axis=2)/255\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        # Достаём имя файла по индексу\n",
        "        image_path = self._image_files[idx]\n",
        "\n",
        "        # Получаем соответствующий файл разметки\n",
        "\n",
        "        image = self.read_image(image_path)\n",
        "\n",
        "        if self.mode in (\"train\", \"val\"):\n",
        "            mask_path = self._mask_files[idx]\n",
        "            mask = self.read_mask(mask_path)\n",
        "\n",
        "        if self.mode in (\"train\", \"val\"):\n",
        "            sample = {'image': image,\n",
        "                      'mask': mask}\n",
        "        else:\n",
        "            sample = {\"image\": image}\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "            \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._image_files)\n",
        "\n",
        "    # Метод для проверки состояния датасета\n",
        "    def make_report(self):\n",
        "        reports = []\n",
        "        if (not self.data_folder):\n",
        "            reports.append(\"data folder path is not given\")\n",
        "        if (len(self._image_files) == 0):\n",
        "            reports.append(\"No images were loaded\")\n",
        "        else:\n",
        "            reports.append(f\"Found {len(self._image_files)} images\")\n",
        "        if (len(self._mask_files) == 0):\n",
        "            reports.append(\"No masks were loaded\")\n",
        "        else:\n",
        "            reports.append(f\"Found {len(self._mask_files)} masks\")\n",
        "        return reports\n"
      ],
      "metadata": {
        "id": "mpisEXHVoZGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g-ybm_WP_Pn"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AbdullahSarhan/ICPRVessels/"
      ],
      "metadata": {
        "id": "dKRearlnuadU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_criterion():\n",
        "    \n",
        "    soft_dice = SoftDice()\n",
        "    def exp_dice(pred, target):\n",
        "        return 1 - soft_dice(torch.exp(pred[:, 1:]), target[:, 1:])\n",
        "\n",
        "    return exp_dice\n",
        "\n",
        "criterion = make_criterion()"
      ],
      "metadata": {
        "id": "zlSgK4jmjFgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "batch_size=1\n",
        "encoder_pretrain='timm-regnety_064'\n",
        "lr_e_pretrain =  1e-5\n",
        "lr_d_pretrain = 1e-3\n",
        "pretrain_data_folder='/content/ICPRVessels/Vessels-Datasets'"
      ],
      "metadata": {
        "id": "jPB009bTkQrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/ICPRVessels/Vessels-Datasets/DRIVE/Test/Original/labels /content/ICPRVessels/Vessels-Datasets/DRIVE/Test/Original/Labels"
      ],
      "metadata": {
        "id": "l_V5nMRt1AC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wlr-ALdIzu6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install madgrad"
      ],
      "metadata": {
        "id": "xWMe4ouOoycf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import madgrad"
      ],
      "metadata": {
        "id": "K-YzMfpwvhu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 1024\n",
        "train_list = [A.Resize(1624,1232),\n",
        "              A.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC),\n",
        "              A.PadIfNeeded(size, size),\n",
        "              ToTensorV2(transpose_mask=True),\n",
        "              ]\n",
        "\n",
        "transforms = {'train': train_list}\n",
        "\n",
        "dataset_pretrain = PngEyeDataset(\n",
        "    pretrain_data_folder, \n",
        "    mode=\"train\",\n",
        "    transform=A.Compose(transforms['train'])\n",
        ")\n",
        "for msg in dataset_pretrain.make_report():\n",
        "    print(msg)\n",
        "\n",
        "pretrain_loader = torch.utils.data.DataLoader(dataset_pretrain, batch_size,\n",
        "                                num_workers=cores,\n",
        "                                shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model_pretrain = smp.UnetPlusPlus(encoder_pretrain, activation='logsoftmax', classes=2, encoder_weights=None).cuda()\n",
        "optimizer = madgrad.MADGRAD(model_pretrain.parameters(), 1e-4)\n",
        "trainer_pretrain = UnetTrainer(model_pretrain, optimizer, criterion, 'cuda', metric_functions=make_metrics())\n",
        "summary = trainer_pretrain.fit(pretrain_loader, 10)\n",
        "torch.save(model_pretrain, \"/content/drive/MyDrive/Competitions/LeadersOfDigital/models/model_pretrain.pt\")"
      ],
      "metadata": {
        "id": "yQGmZY0STB6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "M2hw9hBOna89"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e1Vh2CoDrycd",
        "6TWl-2tSVQlD",
        "evbYchORoWMe"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}